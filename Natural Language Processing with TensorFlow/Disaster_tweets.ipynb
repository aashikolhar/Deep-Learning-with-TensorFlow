{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Disaster_tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H2TU1TEqFQm"
      },
      "source": [
        "#Natural Language Processing with Disaster Tweets\n",
        "##Predict which Tweets are about real disasters and which ones are not\n",
        "Each sample in the train and test set has the following information:\n",
        "\n",
        "- The `text` of a tweet\n",
        "- A `keyword` from that tweet (although this may be blank!)\n",
        "- The `location` the tweet was sent from (may also be blank)\n",
        "\n",
        "We are predicting whether a given tweet is about a real disaster or not. If so, predict a 1. If not, predict a 0.\n",
        "\n",
        "Files\n",
        "- [Disaster_tweets_train](https://github.com/aashikolhar/Deep-Learning-with-TensorFlow/blob/main/Natural%20Language%20Processing%20with%20TensorFlow/Disaster_tweets_train.csv)\n",
        "- [Disaster_tweets_test](https://github.com/aashikolhar/Deep-Learning-with-TensorFlow/blob/main/Natural%20Language%20Processing%20with%20TensorFlow/Disaster_tweets_test.csv)\n",
        "\n",
        "`Columns id` - a unique identifier for each tweet\n",
        "\n",
        "`text` - the text of the tweet\n",
        "\n",
        "`location` - the location the tweet was sent from (may be blank)\n",
        "\n",
        "`keyword` - a particular keyword from the tweet (may be blank)\n",
        "\n",
        "`target` - in train.csv only, this denotes whether a tweet is about a real disaster - (1) or not (0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "676XTCQoffYR",
        "outputId": "6f099b2d-398d-431d-abef-ef4765ee1659"
      },
      "source": [
        "# Loading the training data\n",
        "import pandas as pd\n",
        "data_df = pd.read_csv(\"Disaster_tweets_train.csv\")\n",
        "data_df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NIcvbih20r_z",
        "outputId": "905fa870-4771-4c25-8219-7bc083c35168"
      },
      "source": [
        "# Shuffling the loaded training data\n",
        "data_df_shuffled = data_df.sample(frac=1, axis=0, random_state=42)\n",
        "data_df_shuffled.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uHjt7Cm1G17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3920f8-d8eb-475b-f1fd-e4ba18c1d6b1"
      },
      "source": [
        "# Splitting the training data into train and validation datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(data_df_shuffled[\"text\"].to_list(),\n",
        "                                                                            data_df_shuffled[\"target\"].to_list(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNrnu7z2JZ-i",
        "outputId": "7c44ef05-dfd4-4aa8-ed4a-60d797d1fb78"
      },
      "source": [
        "# Viewing the first 5 train sentences and train labels\n",
        "train_sentences[:5], val_labels[:5]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "  'Imagine getting flattened by Kurt Zouma',\n",
              "  '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "  \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "  'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              " [0, 0, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXPzt1RSGqC7",
        "outputId": "618107fc-71f8-49fa-9b61-e92a59d72e5e"
      },
      "source": [
        "# Creating a list showing the length of each sentence in the training set \n",
        "length_of_sentence = [len(sentence.split()) for sentence in train_sentences]\n",
        "# Viewing the length of the first 5 train_sentences\n",
        "length_of_sentence[:5]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 6, 20, 12, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "IqjvrMmFLPei",
        "outputId": "dd097eb0-6a36-4af4-d633-03165abed358"
      },
      "source": [
        "# Check the distribution of the length of sentences in train_sentences\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(length_of_sentence)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 106.,  424.,  810., 1108., 1176., 1301.,  983.,  637.,  252.,\n",
              "          54.]),\n",
              " array([ 1.,  4.,  7., 10., 13., 16., 19., 22., 25., 28., 31.]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSUQSAUALt_N",
        "outputId": "1d5b48d1-8cc6-40ed-d1ee-eba5845c0653"
      },
      "source": [
        "# Maximum length of the sentence in train_sentences\n",
        "max(length_of_sentence)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrTT-L5wPkXy",
        "outputId": "94ba3567-406e-455a-c4c7-5c9435049e3f"
      },
      "source": [
        "# Length of the sentence which covers 95% of the sentences in train_sentences\n",
        "import numpy as np\n",
        "max_length = int(np.percentile(length_of_sentence, 95))\n",
        "max_length"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Jo-eqaPuJ3"
      },
      "source": [
        "# Defining the parameters for tokenizing train_sentences\n",
        "NUM_WORDS = 10000 # size of our vocabulary\n",
        "MAX_LEN = 24 # choosing 24 as it covers 95% of the train_sentences"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHNpsE4eoxaq"
      },
      "source": [
        "# Tokenizing the sentences\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token = \"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
        "val_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
        "val_padded = pad_sequences(val_sequences, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4SmnUBpoxc2"
      },
      "source": [
        "# Converting the train and validation labels into numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "val_labels = np.array(val_labels)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n8GT-dhpvUm",
        "outputId": "105f02e7-c981-41a4-e737-51a36f05e972"
      },
      "source": [
        "# Build the model (Using Sequential API of keras)\n",
        "# The model consists of Conv1D layer, Bidirectional layer using LSTM and a final Dense layer \n",
        "model = tf.keras.Sequential([\n",
        " tf.keras.layers.Embedding(input_dim=NUM_WORDS, output_dim=128, input_length=MAX_LEN),\n",
        " tf.keras.layers.Conv1D(filters=10, kernel_size=3, activation=\"relu\"),\n",
        " tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(10, return_sequences=True )),\n",
        " tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(10)),\n",
        " tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(train_padded,\n",
        "            train_labels,\n",
        "            epochs=15,\n",
        "            validation_data=(val_padded, val_labels))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "215/215 [==============================] - 18s 49ms/step - loss: 0.5230 - accuracy: 0.7383 - val_loss: 0.4585 - val_accuracy: 0.7979\n",
            "Epoch 2/15\n",
            "215/215 [==============================] - 10s 45ms/step - loss: 0.3216 - accuracy: 0.8770 - val_loss: 0.4592 - val_accuracy: 0.8018\n",
            "Epoch 3/15\n",
            "215/215 [==============================] - 10s 46ms/step - loss: 0.2230 - accuracy: 0.9207 - val_loss: 0.5068 - val_accuracy: 0.8005\n",
            "Epoch 4/15\n",
            "215/215 [==============================] - 9s 43ms/step - loss: 0.1552 - accuracy: 0.9495 - val_loss: 0.5878 - val_accuracy: 0.7769\n",
            "Epoch 5/15\n",
            "215/215 [==============================] - 10s 45ms/step - loss: 0.1057 - accuracy: 0.9631 - val_loss: 0.6441 - val_accuracy: 0.7730\n",
            "Epoch 6/15\n",
            "215/215 [==============================] - 10s 46ms/step - loss: 0.0739 - accuracy: 0.9746 - val_loss: 0.7827 - val_accuracy: 0.7717\n",
            "Epoch 7/15\n",
            "215/215 [==============================] - 10s 44ms/step - loss: 0.0534 - accuracy: 0.9793 - val_loss: 0.8737 - val_accuracy: 0.7756\n",
            "Epoch 8/15\n",
            "215/215 [==============================] - 10s 46ms/step - loss: 0.0437 - accuracy: 0.9819 - val_loss: 1.0990 - val_accuracy: 0.7507\n",
            "Epoch 9/15\n",
            "215/215 [==============================] - 10s 45ms/step - loss: 0.0483 - accuracy: 0.9809 - val_loss: 0.9744 - val_accuracy: 0.7743\n",
            "Epoch 10/15\n",
            "215/215 [==============================] - 9s 43ms/step - loss: 0.0370 - accuracy: 0.9823 - val_loss: 1.0761 - val_accuracy: 0.7782\n",
            "Epoch 11/15\n",
            "215/215 [==============================] - 9s 43ms/step - loss: 0.0454 - accuracy: 0.9819 - val_loss: 1.0898 - val_accuracy: 0.7638\n",
            "Epoch 12/15\n",
            "215/215 [==============================] - 9s 43ms/step - loss: 0.0322 - accuracy: 0.9834 - val_loss: 1.2224 - val_accuracy: 0.7533\n",
            "Epoch 13/15\n",
            "215/215 [==============================] - 10s 46ms/step - loss: 0.0316 - accuracy: 0.9844 - val_loss: 1.2138 - val_accuracy: 0.7388\n",
            "Epoch 14/15\n",
            "215/215 [==============================] - 10s 45ms/step - loss: 0.0281 - accuracy: 0.9857 - val_loss: 1.2572 - val_accuracy: 0.7585\n",
            "Epoch 15/15\n",
            "215/215 [==============================] - 9s 44ms/step - loss: 0.0242 - accuracy: 0.9876 - val_loss: 1.4011 - val_accuracy: 0.7585\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe808b3490>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXFIPUCGqeKz",
        "outputId": "7ead61d7-e694-4367-b40f-4b1ed1d0fa1e"
      },
      "source": [
        "model.evaluate(val_padded, val_labels)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 7ms/step - loss: 1.4011 - accuracy: 0.7585\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4011107683181763, 0.7585301995277405]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f5Mwwpx-rIrI",
        "outputId": "82c8d6d2-4e58-4844-89d3-2d4fd87869d9"
      },
      "source": [
        "# Loading the test data\n",
        "import pandas as pd\n",
        "data_test = pd.read_csv(\"Disaster_tweets_test.csv\")\n",
        "data_test.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHBxDnsLrgcB",
        "outputId": "dbefdf0d-4b19-4770-ac79-7a70785caaec"
      },
      "source": [
        "# Creating a list of only text column from test data\n",
        "test_sentences = data_test[\"text\"].to_list()\n",
        "# Viewing the first 5 examples in test data\n",
        "test_sentences[:5]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Just happened a terrible car crash',\n",
              " 'Heard about #earthquake is different cities, stay safe everyone.',\n",
              " 'there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all',\n",
              " 'Apocalypse lighting. #Spokane #wildfires',\n",
              " 'Typhoon Soudelor kills 28 in China and Taiwan']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HsOlQoRrpUq"
      },
      "source": [
        "# Tokenizing the test_sentences\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbTy0lEMsBI5",
        "outputId": "d97fe02a-aae8-4640-e3a7-b863292f7b6d"
      },
      "source": [
        "# Making predictions on the test data\n",
        "model_preds = tf.round(model.predict(test_padded))\n",
        "# Viewing the first 10 predictions\n",
        "model_preds[:10]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9oW6aNSRDec"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}